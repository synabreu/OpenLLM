{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#영한 모델인 LLAMA 기반의 KoAlpaca 모델로 QA 성공 "
      ],
      "metadata": {
        "id": "QojMrfRagCca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiZkABfNDD7z"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install sentencepiece\n",
        "!pip install bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install loralib\n",
        "!pip install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
        "\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\"beomi/KoAlpaca\")\n",
        "model = LlamaForCausalLM.from_pretrained(\"beomi/KoAlpaca\").to('cuda:0')"
      ],
      "metadata": {
        "id": "Rg2HY8DcDP9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate(**tokenizer('안녕하세요?', return_tensors='pt').to('cuda:0'))"
      ],
      "metadata": {
        "id": "ssfn_jj7dMc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_DICT = {\n",
        "    \"prompt_input\": (\n",
        "        \"Below is an instruction that describes a task, paired with an input that provides further context.\\n\"\n",
        "        \"아래는 작업을 설명하는 명령어와 추가적 맥락을 제공하는 입력이 짝을 이루는 예제입니다.\\n\\n\"\n",
        "        \"Write a response that appropriately completes the request.\\n요청을 적절히 완료하는 응답을 작성하세요.\\n\\n\"\n",
        "        \"### Instruction(명령어):\\n{instruction}\\n\\n### Input(입력):\\n{input}\\n\\n### Response(응답):\"\n",
        "    ),\n",
        "    \"prompt_no_input\": (\n",
        "        \"Below is an instruction that describes a task.\\n\"\n",
        "        \"아래는 작업을 설명하는 명령어입니다.\\n\\n\"\n",
        "        \"Write a response that appropriately completes the request.\\n명령어에 따른 요청을 적절히 완료하는 응답을 작성하세요.\\n\\n\"\n",
        "        \"### Instruction(명령어):\\n{instruction}\\n\\n### Response(응답):\"\n",
        "    ),\n",
        "}"
      ],
      "metadata": {
        "id": "rkYIdftYezuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen(prompt, user_input=None, max_new_tokens=128, temperature=0.8):\n",
        "    if user_input:\n",
        "        x = PROMPT_DICT['prompt_input'].format(instruction=prompt, input=user_input)\n",
        "    else:\n",
        "        x = PROMPT_DICT['prompt_no_input'].format(instruction=prompt)\n",
        "    \n",
        "    input_ids = tokenizer.encode(x, return_tensors=\"pt\").to('cuda:0')\n",
        "    gen_tokens = model.generate(\n",
        "        input_ids, \n",
        "        max_new_tokens=max_new_tokens, \n",
        "        num_return_sequences=1, \n",
        "        temperature=temperature,\n",
        "        no_repeat_ngram_size=6,\n",
        "        do_sample=True,\n",
        "    )\n",
        "    gen_text = tokenizer.decode(gen_tokens[0], skip_special_tokens=True)\n",
        "    \n",
        "    return gen_text.replace(x, '')\n"
      ],
      "metadata": {
        "id": "xbLPJQNvew9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "prompt = \"초거대 언어 모델은 무엇이니?\"\n",
        "generated_text = gen(prompt)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "2U21bOXEfE-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-jM8XBNeffB6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}